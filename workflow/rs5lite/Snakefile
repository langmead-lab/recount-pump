"""
Parameters:
- fastq_dump_args: arguments to pass to fastq dumping tool
- fastq_dump_retries: number of retry attempts before dying
- fastq_dump_tool: name of tool to run, e.g. 'fastq-dump' or 'fasterq-dump'
- star: arguments to pass to STAR aligner
- salmon_args: arguments to pass to salmon quant
- unique_qual: minimum MAPQ needed to be counted in unique BW [default: 10]
- featureCounts: arguments to pass to featureCounts
- fc_unique_qual: minimum MAPQ needed to be counted in unique quantifications [default: 10]
- bw_bed: name of BED file to use with bwtool
- max_unalign: maximum number of unaligned reads to save per run accession
"""

STEPS = ['download', 'fastq_check', 'align', 'sort',
         'bamcount', 'bamcount_unmapped',
         'salmon',
         'align_unmapped',
         'extract_jx',
         'gene_fc_count_all', 'gene_fc_count_unique',
         'exon_fc_count_all', 'exon_fc_count_unique']

FILES = ['sjout.zst', 'fastq_check.tsv.zst',
         'unmapped.fastq.zst',
         'bamcount_nonref.csv.zst',
         'bamcount_auc.tsv',
         'bamcount_frag.tsv',
         'bamcount_jx.tsv.zst',
         'bamcount_unmapped_jx.tsv.zst',
         'bamcount_unmapped_nonref.csv.zst',
         'unmapped_all.bw.zst',
         'unmapped_unique.bw.zst',
         'Chimeric.out.junction.zst',
         'all.gene_fc_count.zst', 'unique.gene_fc_count.zst',
         'all.exon_fc_count.zst', 'unique.exon_fc_count.zst',
         'all.gene_fc_count.summary', 'unique.gene_fc_count.summary',
         'all.exon_fc_count.summary', 'unique.exon_fc_count.summary',
         'all.exon_bw_count.zst', 'unique.exon_bw_count.zst',
         'all.bw.zst',
         'unique.bw.zst',
         'salmon.tsv.zst',
         'jx_bed.zst', 'unmapped.jx_bed.zst',
         'manifest'] + list(map(lambda x: x + '.log', STEPS))

URLS={}
TOKENS={}
READS_IN_BAM=set()

def get_accessions(wildcards):
    """
    Grouping of SRRs with the same SRP could happen here
    """
    for fn in config['input'].split():
        with open(fn, 'r') as fh:
            for ln in fh:
                if ln.count(',') < 2:
                    continue
                toks = ln.rstrip().split(',')
                assert 3 <= len(toks) <= 6
                method = 'sra'
                if len(toks) >= 4:
                    method = toks[3]
                    if len(toks) > 4 and method == 'url':
                        URLS['%s!%s!%s!%s' % (toks[0], toks[1], toks[2], method)]=toks[4].split(';')
                    if len(toks) > 4 and len(toks[4]) > 0 and method == 'gdc':
                        TOKENS['%s!%s!%s!%s' % (toks[0], toks[1], toks[2], method)]=toks[4]
                    if len(toks) > 5 and len(toks[5]) > 0:
                        READS_IN_BAM.add('%s!%s!%s!%s' % (toks[0], toks[1], toks[2], method))
                # SRR,SRP,genome
                # e.g. SRR1557855,SRP045778,ce10
                for ext in FILES:
                    yield os.path.join(config['output'], '%s!%s!%s!%s.%s' % (toks[0], toks[1], toks[2], method, ext))

rule all:
    input:
        get_accessions

rule make_manifest:
    input:
        config['output'] + '/{quad}.salmon.tsv.zst',
        config['output'] + '/{quad}.sjout.zst',
        config['output'] + '/{quad}.jx_bed.zst',
        config['output'] + '/{quad}.unmapped.jx_bed.zst',
        config['output'] + '/{quad}.Chimeric.out.junction.zst',
        config['output'] + '/{quad}.unmapped.fastq.zst',
        config['output'] + '/{quad}.bamcount_jx.tsv.zst',
        config['output'] + '/{quad}.bamcount_nonref.csv.zst',
        config['output'] + '/{quad}.bamcount_auc.tsv',
        config['output'] + '/{quad}.bamcount_frag.tsv',
        config['output'] + '/{quad}.bamcount_unmapped_nonref.csv.zst',
        config['output'] + '/{quad}.unmapped_all.bw.zst',
        config['output'] + '/{quad}.unmapped_unique.bw.zst',
        config['output'] + '/{quad}.fastq_check.tsv.zst',
        config['output'] + '/{quad}.all.gene_fc_count.zst',
        config['output'] + '/{quad}.all.exon_fc_count.zst',
        config['output'] + '/{quad}.unique.gene_fc_count.zst',
        config['output'] + '/{quad}.unique.exon_fc_count.zst',
        config['output'] + '/{quad}.all.gene_fc_count.summary',
        config['output'] + '/{quad}.all.exon_fc_count.summary',
        config['output'] + '/{quad}.unique.gene_fc_count.summary',
        config['output'] + '/{quad}.unique.exon_fc_count.summary',
        config['output'] + '/{quad}.all.exon_bw_count.zst',
        config['output'] + '/{quad}.unique.exon_bw_count.zst',
        config['output'] + '/{quad}.all.bw.zst',
        config['output'] + '/{quad}.unique.bw.zst',
        config['output'] + '/{quad}.align.log',
        config['output'] + '/{quad}.extract_jx.log',
        config['output'] + '/{quad}.bamcount.log',
        config['output'] + '/{quad}.bamcount_unmapped.log',
        config['output'] + '/{quad}.bamcount_unmapped_jx.tsv.zst',
        config['output'] + '/{quad}.align_unmapped.log',
        config['output'] + '/{quad}.download.log',
        config['output'] + '/{quad}.fastq_check.log',
        config['output'] + '/{quad}.sort.log',
        config['output'] + '/{quad}.salmon.log',
        config['output'] + '/{quad}.gene_fc_count_all.log',
        config['output'] + '/{quad}.gene_fc_count_unique.log',
        config['output'] + '/{quad}.exon_fc_count_all.log',
        config['output'] + '/{quad}.exon_fc_count_unique.log'
    output:
        config['output'] + '/{quad}.manifest'
    params:
        quad=lambda wildcards: wildcards.quad
    run:
        with open(output[0], 'wt') as fh:
            for fn in FILES:
                fh.write(params.quad + "." + fn + '\n')
        #all finished, if this exists in URLS, delete
        if params.quad in URLS:
            del URLS[quad]

rule bamcount:
    input:
        bam=config['temp'] + '/{quad}~sorted.bam',
        bamidx=config['temp'] + '/{quad}~sorted.bam.bai',
        exe='/bamcount/bamcount',
        bed=lambda wildcards: '%s/%s/gtf/%s' % (config['ref'], wildcards.quad.split('!')[2], config.get('bw_bed', 'exons.bed'))
    output:
        nonref=config['output'] + '/{quad}.bamcount_nonref.csv.zst',
        auc=config['output'] + '/{quad}.bamcount_auc.tsv',
        frag=config['output'] + '/{quad}.bamcount_frag.tsv',
        all_bw=config['output'] + '/{quad}.all.bw.zst',
        unique_bw=config['output'] + '/{quad}.unique.bw.zst',
        all_bw_count=config['output'] + '/{quad}.all.exon_bw_count.zst',
        unique_bw_count=config['output'] + '/{quad}.unique.exon_bw_count.zst',
        jx=config['output'] + '/{quad}.bamcount_jx.tsv.zst',
    log:
        config['output'] + '/{quad}.bamcount.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        uniq_qual=config.get('unique_qual', 10)
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}_bamcount
        {input.exe} {input.bam} \
            --threads {threads} \
            --coverage \
            --no-head \
            --require-mdz \
            --min-unique-qual {params.uniq_qual} \
            --frag-dist ${{TMP}} \
            --bigwig ${{TMP}} \
            --annotation {input.bed} ${{TMP}} \
            --auc ${{TMP}} \
            --alts ${{TMP}} \
            --junctions ${{TMP}} \
            2>&1 | tee -a {log}

        #
        # --alts
        #

        (time zstd ${{TMP}}.alts.tsv -o {output.nonref}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.nonref})
        echo "COUNT_NonrefSize ${{size}}"
        rm -f ${{TMP}}.alts.tsv

        #
        # --auc
        #
        mv ${{TMP}}.auc.tsv {output.auc}
        size=$(wc -c < {output.auc})
        echo "COUNT_AucSize ${{size}}"
        rm -f ${{TMP}}.auc.tsv

        #
        # --frag-dist
        #
        mv ${{TMP}}.frags.tsv {output.frag}
        size=$(wc -c < {output.frag})
        echo "COUNT_FragDistSize ${{size}}"
        rm -f ${{TMP}}.frags.tsv

        #
        # --bigwig
        #

        (time zstd ${{TMP}}.all.bw -o {output.all_bw}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.all_bw})
        echo "COUNT_BwSize ${{size}}"
        rm -f ${{TMP}}.all.bw

        (time zstd ${{TMP}}.unique.bw -o {output.unique_bw}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.unique_bw})
        echo "COUNT_BwSize ${{size}}"
        rm -f ${{TMP}}.unique.bw
        
        #
        # --junctions
        #
        (time zstd ${{TMP}}.jxs.tsv -o {output.jx}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.jx})
        echo "COUNT_CoJxSize ${{size}}"
        rm -f ${{TMP}}.jxs.tsv

        #
        # --annotation
        #

        (time zstd ${{TMP}}.all.tsv -o {output.all_bw_count}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.all_bw_count})
        echo "COUNT_BwQuantSize ${{size}}"
        rm -f ${{TMP}}.all.tsv

        (time zstd ${{TMP}}.unique.tsv -o {output.unique_bw_count}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.unique_bw_count})
        echo "COUNT_BwQuantSize ${{size}}"
        rm -f ${{TMP}}.unique.tsv

        # Check that all temporaries were properly purged
        set +o pipefail ; num_files=$(ls -d ${{TMP}}* 2>/dev/null | wc -l)
        if (( $num_files > 0 )) ; then
            echo "Failed to purge files (ignore . and ..): $(ls -ad ${{TMP}}*)"
            exit 1
        fi

        echo "COUNT_BamcountComplete 1"
        """

rule bamcount_unmapped:
    input:
        bam=config['temp'] + '/{quad}.unmapped~sorted.bam',
        bamidx=config['temp'] + '/{quad}.unmapped~sorted.bam.bai',
        exe='/bamcount/bamcount'
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        nonref=config['output'] + '/{quad}.bamcount_unmapped_nonref.csv.zst',
        all_bw=config['output'] + '/{quad}.unmapped_all.bw.zst',
        unique_bw=config['output'] + '/{quad}.unmapped_unique.bw.zst',
        jx=config['output'] + '/{quad}.bamcount_unmapped_jx.tsv.zst'
    log:
        config['output'] + '/{quad}.bamcount_unmapped.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        uniq_qual=config.get('unique_qual', 10)
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}_bamcount_unmapped
        {input.exe} {input.bam} \
            --threads {threads} \
            --coverage \
            --no-head \
            --require-mdz \
            --min-unique-qual {params.uniq_qual} \
            --bigwig ${{TMP}} \
            --alts ${{TMP}} \
            --junctions ${{TMP}} \
            2>&1 | tee -a {log}

        #
        # --alts
        #

        (time zstd ${{TMP}}.alts.tsv -o {output.nonref}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.nonref})
        echo "COUNT_NonrefUnmappedSize ${{size}}"
        rm -f ${{TMP}}.alts.tsv

        #
        # --bigwig
        #

        (time zstd ${{TMP}}.all.bw -o {output.all_bw}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.all_bw})
        echo "COUNT_BwUnmappedSize ${{size}}"
        rm -f ${{TMP}}.all.bw

        (time zstd ${{TMP}}.unique.bw -o {output.unique_bw}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.unique_bw})
        echo "COUNT_BwUnmappedSize ${{size}}"
        rm -f ${{TMP}}.unique.bw
        
        #
        # --junctions
        #
        (time zstd ${{TMP}}.jxs.tsv -o {output.jx}) 2>&1 | tee -a {log}
        size=$(wc -c < {output.jx})
        echo "COUNT_CoJxUnmappedSize ${{size}}"
        rm -f ${{TMP}}.jxs.tsv

        echo "COUNT_BamcountComplete 1"
        """

rule bw_zstd:
    input:
        config['temp'] + '/{prefix}.bw'
    output:
        config['output'] + '/{prefix}.bw.zst'
    shell:
        """
        zstd {input} -o {output}
        size=$(wc -c < {output})
        echo "COUNT_BwBytes ${{size}}"
        echo "COUNT_BwZstdComplete 1"
        """

rule gene_fc_count_all:
    input:
        bam=config['temp'] + '/{quad}.bam',  # mates should be together for featureCounts
        gtf=lambda wildcards: '%s/%s/gtf/genes.gtf' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        counts=config['output'] + '/{quad}.all.gene_fc_count.zst',
        summary=config['output'] + '/{quad}.all.gene_fc_count.summary'
    log:
        config['output'] + '/{quad}.gene_fc_count_all.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        fc_param=config.get('featureCounts', '')
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}.gene_fc_count_all.tsv
        TMP2={config[temp]}/{params.srr}.all.gene_count
        (time featureCounts {params.fc_param} -M --primary -O -p -a {input.gtf} -T {threads} \
            -o ${{TMP}} {input.bam}) 2>&1 | tee -a {log}

        test -f ${{TMP}}
        test -f ${{TMP}}.summary

        # Get rid of header and comment, and add SRR to beginning of line
        awk -v OFS='\\t' '$1 !~ /^#/ && $1 !~ /^Geneid/ && $NF != 0 {{print "{params.srr}",$0}}' \
            ${{TMP}} > ${{TMP2}}
        rm -f ${{TMP}}

        (time zstd ${{TMP2}} -o {output.counts}) 2>&1 | tee -a {log}

        size=$(wc -c < {output.counts})
        echo "COUNT_FcCountBytes ${{size}}"
        rm -f ${{TMP2}}

        mv ${{TMP}}.summary {output.summary}

        echo "COUNT_GeneFcCountAllComplete 1"
        """

rule gene_fc_count_unique:
    input:
        bam=config['temp'] + '/{quad}.bam',  # mates should be together for featureCounts
        gtf=lambda wildcards: '%s/%s/gtf/genes.gtf' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        counts=config['output'] + '/{quad}.unique.gene_fc_count.zst',
        summary=config['output'] + '/{quad}.unique.gene_fc_count.summary'
    log:
        config['output'] + '/{quad}.gene_fc_count_unique.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        fc_param=config.get('featureCounts', ''),
        fc_uniq=config.get('fc_unique_qual', 10)
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}.gene_fc_count_unique.tsv
        TMP2={config[temp]}/{params.srr}.unique.gene_count
        (time featureCounts {params.fc_param} -M --primary -Q {params.fc_uniq} -O -p -a {input.gtf} -T {threads} \
            -o ${{TMP}} {input.bam}) 2>&1 | tee -a {log}

        test -f ${{TMP}}
        test -f ${{TMP}}.summary

        # Get rid of header and comment, and add SRR to beginning of line
        awk -v OFS='\\t' '$1 !~ /^#/ && $1 !~ /^Geneid/ && $NF != 0 {{print "{params.srr}",$0}}' \
            ${{TMP}} > ${{TMP2}}
        rm -f ${{TMP}}

        (time zstd ${{TMP2}} -o {output.counts}) 2>&1 | tee -a {log}

        size=$(wc -c < {output.counts})
        echo "COUNT_FcCountBytes ${{size}}"
        rm -f ${{TMP2}}

        mv ${{TMP}}.summary {output.summary}

        echo "COUNT_GeneFcCountUniqueComplete 1"
        """

rule exon_fc_count_all:
    input:
        bam=config['temp'] + '/{quad}.bam',  # mates should be together for featureCounts
        bamidx=config['temp'] + '/{quad}~sorted.bam.bai',
        gtf=lambda wildcards: '%s/%s/gtf/genes.gtf' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        counts=config['output'] + '/{quad}.all.exon_fc_count.zst',
        summary=config['output'] + '/{quad}.all.exon_fc_count.summary'
    log:
        config['output'] + '/{quad}.exon_fc_count_all.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        fc_param=config.get('featureCounts', '')
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}.exon_fc_count_all.tsv
        TMP2={config[temp]}/{params.srr}.all.exon_count
        (time featureCounts {params.fc_param} -O -f -p -a {input.gtf} -T {threads} \
            -o ${{TMP}} {input.bam}) 2>&1 | tee -a {log}

        test -f ${{TMP}}
        test -f ${{TMP}}.summary

        # Get rid of header and comment, and add SRR to beginning of line
        awk -v OFS='\\t' '$1 !~ /^#/ && $1 !~ /^Geneid/ && $NF != 0 {{print "{params.srr}",$0}}' \
            ${{TMP}} > ${{TMP2}}
        rm -f ${{TMP}}

        (time zstd ${{TMP2}} -o {output.counts}) 2>&1 | tee -a {log}

        size=$(wc -c < {output.counts})
        echo "COUNT_FcCountBytes ${{size}}"
        rm -f ${{TMP2}}

        mv ${{TMP}}.summary {output.summary}

        echo "COUNT_ExonFcCountAllComplete 1"
        """

rule exon_fc_count_unique:
    input:
        bam=config['temp'] + '/{quad}.bam',  # mates should be together for featureCounts
        bamidx=config['temp'] + '/{quad}~sorted.bam.bai',
        gtf=lambda wildcards: '%s/%s/gtf/genes.gtf' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        counts=config['output'] + '/{quad}.unique.exon_fc_count.zst',
        summary=config['output'] + '/{quad}.unique.exon_fc_count.summary'
    log:
        config['output'] + '/{quad}.exon_fc_count_unique.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        fc_param=config.get('featureCounts', ''),
        fc_uniq=config.get('fc_unique_qual', 10)
    threads: 4
    shell:
        """
        TMP={config[temp]}/{params.srr}.exon_fc_count_unique.tsv
        TMP2={config[temp]}/{params.srr}.unique.exon_count
        (time featureCounts {params.fc_param} -Q {params.fc_uniq} -O -f -p -a {input.gtf} -T {threads} \
            -o ${{TMP}} {input.bam}) 2>&1 | tee -a {log}

        test -f ${{TMP}}
        test -f ${{TMP}}.summary

        # Get rid of header and comment, and add SRR to beginning of line
        awk -v OFS='\\t' '$1 !~ /^#/ && $1 !~ /^Geneid/ && $NF != 0 {{print "{params.srr}",$0}}' \
            ${{TMP}} > ${{TMP2}}
        rm -f ${{TMP}}

        (time zstd ${{TMP2}} -o {output.counts}) 2>&1 | tee -a {log}

        size=$(wc -c < {output.counts})
        echo "COUNT_FcCountBytes ${{size}}"
        rm -f ${{TMP2}}

        mv ${{TMP}}.summary {output.summary}

        echo "COUNT_ExonFcCountUniqueComplete 1"
        """

rule sort:
    input:
        config['temp'] + '/{quad}.bam'
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        bam=temp(config['temp'] + '/{quad}~sorted.bam'),
        bai=temp(config['temp'] + '/{quad}~sorted.bam.bai')
    log:
        config['output'] + '/{quad}.sort.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        srp=lambda wildcards: wildcards.quad.split('!')[1],
        outdir=config['output'],
        idxstats=config['output'] + '/{quad}.idxstats',
        keep_bam='keep_bam' in config
    threads: 8
    shell:
        """
        TMP="{config[temp]}/sort_temp.{params.srr}"
        mkdir -p ${{TMP}}
        time samtools sort \
            -T ${{TMP}}/samtools_temp \
            -@ {threads} \
            -m 64M \
            -o {output.bam} {input} 2>&1 | tee -a {log}
        rm -rf ${{TMP}}
        size=$(wc -c < {output.bam})
        echo "COUNT_SortedBAMBytes ${{size}}"

        time samtools index -@ {threads} {output.bam} 2>&1 | tee -a {log}

        samtools idxstats {output.bam} > {params.idxstats} 2>> {log}

        #we may want to keep this BAM if its
        #1) part of the simulation set OR
        #2) its part of the config params
        STUDY="{params.srp}"
        BAM='{output.bam}'
        OUTDIR="{params.outdir}"
        KEEP_BAM="{params.keep_bam}"
        `perl -e '$s="'$STUDY'"; $b="'$BAM'"; $o="'$OUTDIR'"; $kb="'$KEEP_BAM'"; if($s=~/SIMULATION/i || $kb=~/true/i) {{ system("cp $b $b.bai $o/"); }}'`
        echo "COUNT_SortComplete 1"
        """

rule sort_unmapped:
    input:
        config['temp'] + '/{quad}.unmapped.bam'
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        bam=temp(config['temp'] + '/{quad}.unmapped~sorted.bam'),
        bai=temp(config['temp'] + '/{quad}.unmapped~sorted.bam.bai')
    log:
        config['output'] + '/{quad}.unmapped.sort.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        srp=lambda wildcards: wildcards.quad.split('!')[1],
        outdir=config['output'],
        idxstats=config['output'] + '/{quad}.unmapped.idxstats'
    threads: 8
    shell:
        """
        TMP="{config[temp]}/sort_temp.{params.srr}"
        mkdir -p ${{TMP}}
        time samtools sort \
            -T ${{TMP}}/samtools_temp \
            -@ {threads} \
            -m 64M \
            -o {output.bam} {input} 2>&1 | tee -a {log}
        rm -rf ${{TMP}}
        size=$(wc -c < {output.bam})
        echo "COUNT_SortedBAMBytes ${{size}}"

        time samtools index -@ {threads} {output.bam} 2>&1 | tee -a {log}

        samtools idxstats {output.bam} > {params.idxstats} 2>> {log}

        cp {output.bam} {output.bam}.bai {params.outdir}/
        echo "COUNT_SortComplete 1"
        """

rule salmon:
    input:
        reads0=config['temp'] + '/{quad}_0.fastq',
        reads1=config['temp'] + '/{quad}_1.fastq',
        reads2=config['temp'] + '/{quad}_2.fastq',
        index1=lambda wildcards: '%s/%s/salmon_index/hash.bin' % (config['ref'], wildcards.quad.split('!')[2]),
        index2=lambda wildcards: '%s/%s/salmon_index/sa.bin' % (config['ref'], wildcards.quad.split('!')[2])
    output:
        config['output'] + '/{quad}.salmon.tsv.zst'
    log:
        config['output'] + '/{quad}.salmon.log'
    params:
        index_base=lambda wildcards: '%s/%s/salmon_index' % (config['ref'], wildcards.quad.split('!')[2]),
        salmon_args=config.get('salmon_args', '')
    threads: 8
    shell:
        """
        READ_FILES="-r {input.reads0}"
        if [[ -s {input.reads2} ]] ; then
            READ_FILES="-1 {input.reads1} -2 {input.reads2}"
        fi
        if set -o pipefail && time salmon quant \
            --libType U \
            --quiet \
            --validateMappings \
            -i {params.index_base} \
            -p {threads} \
            {params.salmon_args} \
            ${{READ_FILES}} \
            --output salmon_quant \
            --minAssignedFrags 1 \
            2>&1 | tee -a {log}
        then
            echo "COUNT_SalmonSuccess 1"

            time zstd salmon_quant/quant.sf -o {output} 2>&1 | tee -a {log}
            size=$(wc -c < {output})
            echo "COUNT_SalmonQuantBytes ${{size}}"
        else
            touch {output}
            echo "COUNT_SalmonFailure 1"
        fi
        rm -rf salmon_quant
        echo "COUNT_SalmonComplete 1"
                
        if [[ -s {input.reads2} && -s {input.reads0} ]] ; then
            READ_FILES="-r {input.reads0}"
            if set -o pipefail && time salmon quant \
                --libType U \
                --quiet \
                --validateMappings \
                -i {params.index_base} \
                -p {threads} \
                {params.salmon_args} \
                ${{READ_FILES}} \
                --output salmon_quant \
                --minAssignedFrags 1 \
                2>&1 | tee -a {log}
            then
                echo "COUNT_SalmonSuccess_unpaired 1"

                time zstd salmon_quant/quant.sf -o {output}.0 2>&1 | tee -a {log}
                size=$(wc -c < {output}.0)
                echo "COUNT_SalmonQuantBytes_unpaired ${{size}}"
            else
                touch {output}.0
                echo "COUNT_SalmonFailure_unpaired 1"
            fi
            rm -rf salmon_quant
            echo "COUNT_SalmonComplete_unpaired 1"
        fi
        """

rule align_unmapped:
    input:
        unmapped1=config['temp'] + '/{quad}_1.unmappedfastq',
        unmapped2=config['temp'] + '/{quad}_2.unmappedfastq',
        index=lambda wildcards: '%s/%s/unmapped_hisat2_idx/genome.1.ht2' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~]+"
    output:
        bam=config['temp'] + '/{quad}.unmapped.bam',
        sample=config['output'] + '/{quad}.unmapped.fastq.zst'
    log:
        config['output'] + '/{quad}.align_unmapped.log'
    params:
        index_base=lambda wildcards: '%s/%s/unmapped_hisat2_idx/genome' % (config['ref'], wildcards.quad.split('!')[2]),
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        hisat2_params=config.get('hisat2', ''),
        max_unalign=config.get('max_unalign', 100000)
    threads: 16
    shell:
        """
        TMP="{config[temp]}/align_unmapped_temp.{params.srr}"
        READ_FILES="-1 {input.unmapped1} -2 {input.unmapped2}"
        if [[ ! -s {input.unmapped2} ]] ; then
            READ_FILES="-U {input.unmapped1}"
        fi
        time hisat2 \
            $READ_FILES \
            -t --mm \
            -x {params.index_base} \
            --threads {threads} \
            {params.hisat2_params} \
            --un ${{TMP}}.un \
            --un-conc ${{TMP}}.un_conc \
            -S ${{TMP}}.sam \
            2>&1 | tee -a {log}

        MAX_UNALIGN={params.max_unalign}
        if [[ -s {input.unmapped1}.0 ]] ; then
            READ_FILES="-U {input.unmapped1}.0"
            time hisat2 \
                $READ_FILES \
                -t --mm \
                -x {params.index_base} \
                --threads {threads} \
                {params.hisat2_params} \
                --un ${{TMP}}.un.0 \
                --un-conc ${{TMP}}.un_conc.0 \
                -S ${{TMP}}.sam.0 \
                2>&1 | tee -a {log}
                
                #now add the extra alignments
                time samtools view -F 4 \
                    ${{TMP}}.sam.0 >> \
                    ${{TMP}}.sam
                rm -f ${{TMP}}.sam.0
 
                #determine how to split up the sampling of unmapped reads
                #in the split3 case 
                NUM_PAIRED_UN=`wc -l ${{TMP}}.1.un_conc | cut -d" " -f 1`
                NUM_UNPAIRED_UN=`wc -l ${{TMP}}.un.0 | cut -d" " -f 1`
                #we prefer sampling from the unmapped paired reads
                #rather than these; only divide paired by 2 since there's 
                #2 of them
                MAX_UNALIGN2=`perl -e '$max='$MAX_UNALIGN'; $np='$NUM_PAIRED_UN'/2; \
                    $npu='$NUM_UNPAIRED_UN'/4; \
                    if($np>=$max) {{ print "".0; }} else {{ print "".($max-$np); }}'`
 
                # split3 unpaired unmapped
                if [[ "$MAX_UNALIGN2" -gt "0" ]] ; then
                    fastq-sample \
                        -n $MAX_UNALIGN2 \
                        -o ${{TMP}}.samp.0 \
                        ${{TMP}}.un.0
                fi
                rm -f ${{TMP}}.un.0
        fi

        #
        # Make BAM file out of aligned reads
        #
        time samtools view \
            -b -F 4 \
            -o {output.bam} \
            ${{TMP}}.sam \
            2>&1 | tee -a {log}
        rm -f ${{TMP}}.sam

        #
        # Save a subset of the doubly unaligned reads
        #
        if [[ ! -s {input.unmapped2} ]] ; then
            # unpaired
            fastq-sample \
                -n $MAX_UNALIGN \
                -o ${{TMP}}.samp \
                ${{TMP}}.un
            rm -f ${{TMP}}.un
        else
            # paired-end
            fastq-sample \
                -n $MAX_UNALIGN \
                -o ${{TMP}}.samp \
                ${{TMP}}.1.un_conc ${{TMP}}.2.un_conc
            rm -f ${{TMP}}.1.un_conc ${{TMP}}.2.un_conc
            
            # interleave the two output fastqs into single file
            paste ${{TMP}}.samp.1.fastq ${{TMP}}.samp.2.fastq \
                | paste - - - - \
                | awk -v OFS="\n" -v FS="\t" '{{print($1,$3,$5,$7,$2,$4,$6,$8)}}' \
                > ${{TMP}}.samp.fastq
            rm -f ${{TMP}}.samp.1.fastq ${{TMP}}.samp.2.fastq
        fi

        test -f ${{TMP}}.samp.fastq
        time zstd ${{TMP}}.samp.fastq -o {output.sample} 2>&1 | tee -a {log}
        size=$(wc -c < {output.sample})
        echo "COUNT_UnmappedSampleBytes ${{size}}"
        rm -f ${{TMP}}.samp.fastq
       
        #handle the split3 case in addition (if it exists) 
        if [[ -s ${{TMP}}.samp.0.fastq ]] ; then
            time zstd ${{TMP}}.samp.0.fastq -o {output.sample}.0 2>&1 | tee -a {log}
            size=$(wc -c < {output.sample}.0)
            echo "COUNT_UnmappedSampleBytes_unpaired ${{size}}"
            rm -f ${{TMP}}.samp.0.fastq
        fi

        size=$(wc -c < {output.bam})
        echo "COUNT_UnmappedBamBytes ${{size}}"

        echo "COUNT_AlignUnmappedComplete 1"
        """

rule extract_jx:
    input:
        bam=config['temp'] + '/{quad}~sorted.bam',
        bamidx=config['temp'] + '/{quad}~sorted.bam.bai',
        fa=lambda wildcards: '%s/%s/fasta/genome.fa' % (config['ref'], wildcards.quad.split('!')[2]),
        gtf=lambda wildcards: '%s/%s/gtf/genes.gtf' % (config['ref'], wildcards.quad.split('!')[2])
    output:
        config['output'] + '/{quad}.jx_bed.zst'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0]
    log:
        config['output'] + '/{quad}.extract_jx.log'
    shell:
        """
        nrecs=$(set +o pipefail ; samtools view {input.bam} | head -n 10 | wc -l)
        echo "nrecs=${{nrecs}}"
        if (( $nrecs == 0 )) ; then
            echo "COUNT_ExtractJxSkipEmpty 1"
            echo "" | zstd -c > {output}
        else
            TMP="{config[temp]}/extract_jx.{params.srr}"
            time regtools junctions extract \
                -i 20 -a 1 \
                -o ${{TMP}}.jx_tmp \
                {input.bam} 2>&1 | tee -a {log}
            time zstd ${{TMP}}.jx_tmp -o {output} 2>&1 | tee -a {log}
            rm -f ${{TMP}}.jx_tmp
    
            size=$(wc -c < {output})
            echo "COUNT_ExtractJxBytes ${{size}}"
        fi
        echo "COUNT_ExtractJxComplete 1"
        """

rule align:
    input:
        reads0=config['temp'] + '/{quad}_0.fastq',
        reads1=config['temp'] + '/{quad}_1.fastq',
        reads2=config['temp'] + '/{quad}_2.fastq',
        index1=lambda wildcards: '%s/%s/star_idx/SAindex' % (config['ref'], wildcards.quad.split('!')[2]),
        index2=lambda wildcards: '%s/%s/star_idx/SA' % (config['ref'], wildcards.quad.split('!')[2])
    wildcard_constraints:
        quad="[^~\.]+"
    output:
        bam=temp(config['temp'] + '/{quad}.bam'),
        jxs=config['output'] + '/{quad}.sjout.zst',
        chimeric=config['output'] + '/{quad}.Chimeric.out.junction.zst',
        unmapped1=config['temp'] + '/{quad}_1.unmappedfastq',
        unmapped2=config['temp'] + '/{quad}_2.unmappedfastq'
    log:
        config['output'] + '/{quad}.align.log'
    params:
        index_base=lambda wildcards: '%s/%s/star_idx' % (config['ref'], wildcards.quad.split('!')[2]),
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        star_params=config.get('star', ''),
        is_simulation=lambda wildcards: 1 if wildcards.quad.split('!')[1] == 'SIMULATION' else 0
    threads: 16
    shell:
        """
        READ_FILES="{input.reads0}"
        if [[ -s {input.reads2} ]] ; then
            READ_FILES="{input.reads1} {input.reads2}"
        fi
        readnames='Number'
        if [[ {params.is_simulation} == "1" ]] ; then
            readnames='Standard'
        fi
        TMP="{config[temp]}/align_temp.{params.srr}"
        rm -rf ${{TMP}}
        time STAR \
            {params.star_params} \
            --runMode alignReads \
            --runThreadN {threads} \
            --genomeDir {params.index_base} \
            --readFilesIn ${{READ_FILES}} \
            --twopassMode None \
            --genomeLoad LoadAndRemove \
            --outTmpDir ${{TMP}} \
            --outReadsUnmapped Fastx \
            --outMultimapperOrder Old_2.4 \
            --outSAMreadID $readnames \
            --outSAMtype BAM Unsorted \
            --outSAMmode NoQS \
            --outSAMattributes NH MD \
            --chimOutType Junctions \
            --chimOutJunctionFormat 1 \
            --chimSegmentReadGapMax 3 \
            --chimJunctionOverhangMin 12 \
            --chimSegmentMin 12 2>&1 | tee -a {log}
   
        # Full set of output files:
        #
        # Aligned.out.bam
        # Chimeric.out.junction
        # Log.final.out
        # Log.out
        # Log.progress.out
        # SJ.out.tab
        # Unmapped.out.mate1
        # Unmapped.out.mate2 (if any reads were paired-end)

        #
        # Logs
        #
        rm -rf ${{TMP}}
        cat Log.out >> {log}
        cat Log.final.out >> {log}
        rm -f Log*.out

        #
        # Junctions
        #
        test -f SJ.out.tab
        time zstd SJ.out.tab -o {output.jxs} 2>&1 | tee -a {log}
        rm -f SJ.out.tab
        size=$(wc -c < {output.jxs})
        echo "COUNT_CompressedJxBytes ${{size}}"

        #
        # Chimerics
        #
        test -f Chimeric.out.junction
        test -s Chimeric.out.junction
        sort -k1,1 -k2,2n Chimeric.out.junction > Chimeric.out.junction.sorted
        time zstd Chimeric.out.junction.sorted -o {output.chimeric} 2>&1 | tee -a {log}
        rm -f Chimeric.out.junction Chimeric.out.junction.sorted
        size=$(wc -c < {output.chimeric})
        echo "COUNT_ChimericBytes ${{size}}"

        #
        # Unmapped
        #
        touch {output.unmapped2}
        test -f Unmapped.out.mate1
        mv Unmapped.out.mate1 {output.unmapped1}
        if [[ -f Unmapped.out.mate2 ]] ; then
            mv Unmapped.out.mate2 {output.unmapped2}
        fi

        #
        # Alignments
        #
        size=$(wc -c < Aligned.out.bam)
        echo "COUNT_BAMBytes ${{size}}"
        mv Aligned.out.bam {output.bam}

        echo "COUNT_AlignComplete 1"
        
        if [[ -s {input.reads2} && -s {input.reads0} ]] ; then
            READ_FILES="{input.reads0}"
            TMP="{config[temp]}/align_temp.{params.srr}.0"
            rm -rf ${{TMP}}
            time STAR \
                {params.star_params} \
                --runMode alignReads \
                --runThreadN {threads} \
                --genomeDir {params.index_base} \
                --readFilesIn ${{READ_FILES}} \
                --twopassMode None \
                --genomeLoad LoadAndRemove \
                --outTmpDir ${{TMP}} \
                --outReadsUnmapped Fastx \
                --outMultimapperOrder Old_2.4 \
                --outSAMreadID $readnames \
                --outSAMtype BAM Unsorted \
                --outSAMmode NoQS \
                --outSAMattributes NH MD \
                --chimOutType Junctions \
                --chimOutJunctionFormat 1 \
                --chimSegmentReadGapMax 3 \
                --chimJunctionOverhangMin 12 \
                --chimSegmentMin 12 2>&1 | tee -a {log}
       
            # Full set of output files:
            #
            # Aligned.out.bam
            # Chimeric.out.junction
            # Log.final.out
            # Log.out
            # Log.progress.out
            # SJ.out.tab
            # Unmapped.out.mate1
            # Unmapped.out.mate2 (if any reads were paired-end)

            #
            # Logs
            #
            rm -rf ${{TMP}}
            cat Log.out >> {log}
            cat Log.final.out >> {log}
            rm -f Log*.out

            #
            # Junctions
            #
            test -f SJ.out.tab
            if [[ -s {output.jxs} ]] ; then
                cat <(zstd -cd {output.jxs}) SJ.out.tab | sort -k1,1 -k2,2n -k3,3n -k4,4n -k5,5n -k6,6n | perl -ne 'chomp; $f=$_; @f=split(/\t/,$f); ($c,$s,$e,$o,$motif,$annot,$nu,$nmm,$max_anchor)=@f; $k=join("\t",($c,$s,$e,$o,$motif,$annot)); if($pk) {{ if($pk eq $k) {{ $pnu+=$nu; $pnmm+=$nmm; $pmax_anchor = $max_anchor > $pmax_anchor?$max_anchor:$pmax_anchor; next; }} print "$pk\t$pnu\t$pnmm\t$pmax_anchor\n"; }} $pk=$k; $pnu=$nu; $pnmm=$nmm; $pmax_anchor=$max_anchor; END {{ if($pk) {{ print "$pk\t$pnu\t$pnmm\t$pmax_anchor\n"; }} }}' > sjout.all.merged
                time zstd -f sjout.all.merged -o {output.jxs} 2>&1 | tee -a {log}
                rm -f SJ.out.tab
            else
                time zstd -f SJ.out.tab -o {output.jxs} 2>&1 | tee -a {log}
            fi
            size=$(wc -c < {output.jxs})
            echo "COUNT_CompressedJxBytes_both ${{size}}"

            #
            # Chimerics
            #
            test -f Chimeric.out.junction
            test -s Chimeric.out.junction
            #now join them with the first run chimerics
            if [[ -s {output.chimeric} ]] ; then
                cat <(zstd -cd {output.chimeric}) Chimeric.out.junction | sort -k1,1 -n -k2,2 > Chimeric.out.junction.sorted
            else
                cat Chimeric.out.junction | sort -k1,1 -k2,2n > Chimeric.out.junction.sorted
            fi
            time zstd -f Chimeric.out.junction.sorted -o {output.chimeric} 2>&1 | tee -a {log}
            rm -f Chimeric.out.junction Chimeric.out.junction.sorted
            size=$(wc -c < {output.chimeric})
            echo "COUNT_ChimericBytes_both ${{size}}"

            #
            # Unmapped
            #
            test -f Unmapped.out.mate1
            mv Unmapped.out.mate1 {output.unmapped1}.0

            #
            # Alignments
            #
            size=$(wc -c < Aligned.out.bam)
            echo "COUNT_BAMBytes_unpaired ${{size}}"
            mv Aligned.out.bam {output.bam}.0

            echo "COUNT_AlignComplete_unpaired 1"

            #now cat the 2 BAMs
            samtools cat {output.bam} {output.bam}.0 -o {output.bam}.2
            mv {output.bam}.2 {output.bam}
            rm {output.bam}.0
        fi
        """

rule fastq_check:
    input:
        reads0=config['temp'] + '/{quad}_0.fastq',
        reads1=config['temp'] + '/{quad}_1.fastq',
        reads2=config['temp'] + '/{quad}_2.fastq'
    output:
        config['output'] + '/{quad}.fastq_check.tsv.zst'
    log:
        config['output'] + '/{quad}.fastq_check.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0]
    shell:
        """
        TMP="{config[temp]}/fastq_check-{params.srr}.tsv"
        touch ${{TMP}}
        if [[ -s {input.reads0} ]] ; then
            time seqtk fqchk -q0 {input.reads0} >>${{TMP}} 2>>{log}
        fi
        if [[ -s {input.reads1} ]] ; then
            time seqtk fqchk -q0 {input.reads1} >>${{TMP}} 2>>{log}
        fi
        if [[ -s {input.reads2} ]] ; then
            time seqtk fqchk -q0 {input.reads2} >>${{TMP}} 2>>{log}
        fi
        time zstd ${{TMP}} -o {output} 2>&1 | tee -a {log}
        size=$(wc -c < {output})
        echo "COUNT_FastqCheckBytes ${{size}}"

        echo "COUNT_FastqCheckComplete 1"
        """

rule download:
    input:
        exe='/bamcount/bamcount'
    output:
        temp(config['temp'] + '/{quad}_0.fastq'),
        temp(config['temp'] + '/{quad}_1.fastq'),
        temp(config['temp'] + '/{quad}_2.fastq')
    wildcard_constraints:
        quad="[^~\.]+"
    log:
        config['output'] + '/{quad}.download.log'
    params:
        srr=lambda wildcards: wildcards.quad.split('!')[0],
        study=lambda wildcards: wildcards.quad.split('!')[1],
        method=lambda wildcards: wildcards.quad.split('!')[3],
        fd_params=config.get('fastq_dump_args', ''),
        retries=config.get('fastq_dump_retries', '5'),
        url1=lambda wildcards: URLS[wildcards.quad][0] if wildcards.quad in URLS and len(URLS[wildcards.quad]) > 0 else None,
        url2=lambda wildcards: URLS[wildcards.quad][1] if wildcards.quad in URLS and len(URLS[wildcards.quad]) > 1 else None,
        url0=lambda wildcards: URLS[wildcards.quad][2] if wildcards.quad in URLS and len(URLS[wildcards.quad]) > 2 else None,
        num_urls=lambda wildcards: len(URLS[wildcards.quad]) if wildcards.quad in URLS else 0,
        is_gzipped=lambda wildcards: 1 if wildcards.quad in URLS and URLS[wildcards.quad][0][-3:] == '.gz' else 0,
        gdc_token=lambda wildcards: TOKENS[wildcards.quad] if wildcards.quad in TOKENS else "",
        reads_in_bam=lambda wildcards: 1 if wildcards.quad in READS_IN_BAM else 0
    threads: 4
    shell:
        """
        set -xeo pipefail
        SUCCESS=0
        TIMEOUT=10
        PARAMS=""
        TMP="{config[temp]}/dl-{params.srr}"
        ! test -d ${{TMP}}
        
        if [[ {params.method} == "sra" ]] ; then
            USE_FASTERQ=1
            for i in {{ 1..{params.retries} }} ; do
                if time prefetch --max-size 200G -t fasp -O ${{TMP}} -L info {params.srr} 2>&1 >> {log} ; then
                    SUCCESS=1
                    break
                else
                    echo "COUNT_SraRetries 1"
                    TIMEOUT=$((${{TIMEOUT}} * 2))
                    sleep ${{TIMEOUT}}
                fi
            done
            if (( $SUCCESS == 0 )) ; then
                echo "COUNT_SraFailures 1"
                exit 1
            fi
            test -f ${{TMP}}/*.sra
            size=$(cat ${{TMP}}/*.sra | wc -c)
            echo "COUNT_SraBytesDownloaded ${{size}}"
            if (( ${{USE_FASTERQ}} == 1 )) ; then
                time parallel-fastq-dump --sra-id ${{TMP}}/*.sra \
                    --threads {threads} \
                    --tmpdir ${{TMP}} \
                    -L info \
                    --split-3 \
                    --skip-technical \
                    --outdir . \
                    2>&1 >> {log}
                test -f {params.srr}_2.fastq || \
                    (test -f {params.srr}_1.fastq && mv {params.srr}_1.fastq {params.srr}_0.fastq) || \
                                    (test -f {params.srr}.fastq && mv {params.srr}.fastq {params.srr}_0.fastq)
                # extra unpaired from --split-3
                test -f {params.srr}_2.fastq && test -f {params.srr}.fastq && mv {params.srr}.fastq {params.srr}_0.fastq
            else
                time fastq-dump ${{TMP}}/*.sra \
                    -L info \
                    --split-3 \
                    --skip-technical \
                    -O . \
                    2>&1 >> {log}
                test -f {params.srr}_2.fastq || \
                    (test -f {params.srr}_1.fastq && mv {params.srr}_1.fastq {params.srr}_0.fastq) || \
                                    (test -f {params.srr}.fastq && mv {params.srr}.fastq {params.srr}_0.fastq)
                # extra unpaired from --split-3
                test -f {params.srr}_2.fastq && test -f {params.srr}.fastq && mv {params.srr}.fastq {params.srr}_0.fastq
            fi
            rm -rf ${{TMP}}
        elif [[ {params.method} == "gdc" ]] ; then
            TOKEN={params.gdc_token}
            use_token="-t ${{TOKEN}}"
            #if we have a token but it doesn't exist, throw an error
            if [[ ! -z ${{TOKEN}} && ! -f ${{TOKEN}} ]] ; then
                echo "ERROR: no GDC token file found at ${{TOKEN}}"
                exit 1
            elif [[ -z ${{TOKEN}} ]] ; then
                #e.g. CCLE
                use_token=""
            fi
            mkdir -p ${{TMP}}
            for i in {{ 1..{params.retries} }} ; do
                if time gdc-client download \
                    $use_token --log-file ${{TMP}}/log.txt \
                    -n {threads} \
                    -d ${{TMP}} \
                    --no-verify \
                    --no-annotations \
                    --retry-amount {params.retries} \
                    --wait-time 3 \
                    {params.srr} 2>&1 >> {log}
                then
                    SUCCESS=1
                    break
                else
                    echo "COUNT_GdcRetries 1"
                    TIMEOUT=$((${{TIMEOUT}} * 2))
                    sleep ${{TIMEOUT}}
                fi
            done
            if (( $SUCCESS == 0 )) ; then
                echo "COUNT_GdcFailures 1"
                exit 1
            fi
            test -d ${{TMP}}/{params.srr}
            if [[ {params.study} == "ccle" || {params.reads_in_bam} -eq 1 ]] ; then
                test -f ${{TMP}}/{params.srr}/*.bam
                echo "=== gdc-client log.txt begin ===" >> {log}
                cat ${{TMP}}/log.txt >> {log}
                echo "=== gdc-client log.txt end===" >> {log}
                
                size=$(cat ${{TMP}}/{params.srr}/*.bam | wc -c)
                echo "COUNT_GdcBytesDownloaded ${{size}}"
                BAM=$(ls ${{TMP}}/{params.srr}/*.bam)
                {input.exe} $BAM --threads {threads} --bam2fastq {params.srr} --filter-out 256 --re-reverse 2>&1 >> {log}
                
                test -s {params.srr}.fastq && \
                    mv {params.srr}.fastq {params.srr}_0.fastq
            else
                test -f ${{TMP}}/{params.srr}/*.tar.gz
                
                echo "=== gdc-client log.txt begin ===" >> {log}
                cat ${{TMP}}/log.txt >> {log}
                echo "=== gdc-client log.txt end===" >> {log}
                
                size=$(cat ${{TMP}}/{params.srr}/*.tar.gz | wc -c)
                echo "COUNT_GdcBytesDownloaded ${{size}}"

                tar zxvf ${{TMP}}/{params.srr}/*.tar.gz
                rm -rf ${{TMP}}

                num_1s=$(ls -1 *_1.fastq | wc -l)
                num_2s=$(ls -1 *_2.fastq | wc -l)
                if (( ${{num_1s}} == 0 )) ; then
                    echo "ERROR: No _1.fastq files output"
                    exit 1
                fi
                if (( ${{num_1s}} > 1 )) ; then
                    echo "ERROR: More than one _1.fastq file found"
                    exit 1
                fi
                if (( ${{num_2s}} == 0 )) ; then
                    # unpaired
                    mv *_1.fastq {params.srr}_0.fastq
                else
                    # paired-end
                    mv *_1.fastq {params.srr}_1.fastq
                    mv *_2.fastq {params.srr}_2.fastq
                fi
            fi
        elif [[ {params.method} == "url" ]] ; then
            additional_cmd='cat'
            if [[ {params.is_gzipped} == "1" ]] ; then
                additional_cmd='gzip -cd'
            fi
            for i in {{ 1..{params.retries} }} ; do
                if time curl "{params.url1}" 2>> {log} | $additional_cmd > {params.srr}_0.fastq 2>> {log} ; then
                    SUCCESS=1
                    break
                else
                    echo "COUNT_URLRetries1 1"
                    TIMEOUT=$((${{TIMEOUT}} * 2))
                    sleep ${{TIMEOUT}}
                fi
            done
            if (( $SUCCESS == 1 )) && [[ {params.num_urls} -gt 1 ]] ; then
                SUCCESS=0
                for i in {{ 1..{params.retries} }} ; do
                    if time curl "{params.url2}" 2>> {log} | $additional_cmd > {params.srr}_2.fastq 2>> {log} ; then
                        SUCCESS=1
                        mv {params.srr}_0.fastq {params.srr}_1.fastq
                        break
                    else
                        echo "COUNT_URLRetries2 1"
                        TIMEOUT=$((${{TIMEOUT}} * 2))
                        sleep ${{TIMEOUT}}
                    fi
                done
            fi
            if (( $SUCCESS == 1 )) && [[ {params.num_urls} -gt 2 ]] ; then
                SUCCESS=0
                for i in {{ 1..{params.retries} }} ; do
                    if time curl "{params.url0}" 2>> {log} | $additional_cmd > {params.srr}_0.fastq 2>> {log} ; then
                        SUCCESS=1
                        break
                    else
                        echo "COUNT_URLRetries0 1"
                        TIMEOUT=$((${{TIMEOUT}} * 2))
                        sleep ${{TIMEOUT}}
                    fi
                done
            fi
            if (( $SUCCESS == 0 )) ; then
                echo "COUNT_URLFailures 1"
                exit 1
            fi
        fi
        
        # Next chunk expects the FASTQ files to exist in the current directory
        # named {{params.srr}}_{{0,1,2}}.fastq
        size=0
        for i in {{0..2}} ; do
            fn={params.srr}_${{i}}.fastq
            if [[ -f ${{fn}} ]] ; then
                echo "COUNT_FilesDownloaded 1"
            else
                touch ${{fn}}
            fi
            size=$((${{size}} + $(wc -c < ${{fn}})))
            mv ${{fn}} {config[temp]}/{wildcards.quad}_${{i}}.fastq
        done
        echo "COUNT_BytesDownloaded ${{size}}"
        echo "COUNT_DownloadComplete 1"
        """
